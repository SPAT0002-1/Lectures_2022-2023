{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian inference: Basics\n",
    "\n",
    "## Table of Content:\n",
    "\n",
    "- I [Frequentist vs Bayesian inference](#I.-Frequentist-vs-Bayesian-Approaches)\n",
    "- II [The Bayesian Problem Setting](#II.-The-Bayesian-Problem-Setting)\n",
    "- III [The Bayes' theorem / Bayes' Rule](#III-The-Bayes'-theorem-/-Bayes'-Rule):\n",
    "- IV Simple Bayesian Modeling: See [Bayes_simple_modeling.ipynb](Bayes_simple_modeling.ipynb)\n",
    "- V Bayesian modeling with Monte Carlo Markov Chains (MCMC): See [Bayes_MCMC.ipynb](Bayes_MCMC.ipynb)\n",
    "- XX [Referemces](#XX-References:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Frequentist vs Bayesian Approaches\n",
    "\n",
    "Both the model fitting and model selection problems can be approached from either a *frequentist* or a *Bayesian* standpoint. The \"philosophical\" difference between the two approaches will not be discussed in details. The interested reader (ideally already familiar with Bayesian statistics) may read [Bayes_philosophy.ipynb](Bayes_philosophy.ipynb) and [J. VanderPlass blog posts](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) to get mor insights on this question. We propose to review the formalism of Bayes statistics in the next Section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. The Bayesian Problem Setting\n",
    "\n",
    "The end-goal of a Bayesian analysis is a probabilistic statement about the universe.\n",
    "Roughly we want to measure\n",
    "\n",
    "$$\n",
    "P(science)\n",
    "$$\n",
    "\n",
    "Where \"science\" might be encapsulated in the cosmological model, the mass of a planet around a star, or whatever else we're interested in learning about.\n",
    "\n",
    "We don't of course measure this without reference to data, so more specifically we want to measure\n",
    "\n",
    "$$\n",
    "P(science~|~data)\n",
    "$$\n",
    "\n",
    "which should be read \"the probability of the science *given* the data.\"\n",
    "\n",
    "Of course, we should be explicit that this measurement is not done in a vaccum: generally before observing any data we have *some* degree of background information that informs the science, so we should actually write\n",
    "\n",
    "$$\n",
    "P(science~|~data, background\\ info)\n",
    "$$\n",
    "\n",
    "This should be read \"the probability of the science given the data *and* the background information\".\n",
    "\n",
    "Finally, there are often things in the scientific model that we don't particularly care about: these are known as \"nuisance parameters\". As an example of a nuisance parameter, if you are finding a planet in radial velocity data, the secular motion of the star is *extremely* important to model correctly, but in the end you don't really care about the best-fit value of this velocity. This is an example of nuisance parameter. \n",
    "\n",
    "With that in mind, we can write:\n",
    "\n",
    "$$\n",
    "P(science,nuisance\\ parameters~|~data, background\\ info)\n",
    "$$\n",
    "\n",
    "Where as before the comma should be read as an \"and\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we write this down:\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta}_S, \\boldsymbol{\\theta}_N~|~D, I)\n",
    "$$\n",
    "\n",
    "- $\\boldsymbol{\\theta}_S$ represents the \"science\": the set of parameters that we are interested in constraining\n",
    "- $\\boldsymbol{\\theta}_N$ represents the \"nuisance parameters\": the set of parameters that are important in the model, but are not particularly interesting for the scientific result.\n",
    "- $D$ represents the \"observed data\"\n",
    "- $I$ represents the information or knowledge you had before observing the data, including whatever made you choose the model you're fitting.\n",
    "\n",
    "Finally, we'll often just write $\\boldsymbol{\\theta} = (\\boldsymbol{\\theta}_S, \\boldsymbol{\\theta}_N)$ as a shorthand for all the model parameters.\n",
    "\n",
    "This quantity, $P(\\boldsymbol{\\theta}~|~D,I)$ is called the \"posterior probability\" and determining this quantity is the ultimate goal of a Bayesian analysis.\n",
    "\n",
    "Now all we need to do is compute it!\n",
    "\n",
    "The core problem is this: **We do not have a way to directly calculate** $P(\\boldsymbol{\\theta}~|~D,I)$. We often do have an expression for $P(D~|~\\boldsymbol{\\theta},I)$, but these two expressions are **not** equal.\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta}~|~D,I) \\ne P(D~|~\\boldsymbol{\\theta},I)\n",
    "$$\n",
    "\n",
    "\n",
    "The way these two expressions are related is through the Bayes' theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III The Bayes' theorem / Bayes' Rule\n",
    "\n",
    "The definition of conditional probability is entirely symmetric, so we can write\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(B \\cap A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(A\\mid B)\\,P(B) = P(B\\mid A)\\,P(A)\n",
    "$$\n",
    "\n",
    "which is more commonly rearranged in this form:\n",
    "\n",
    "$$\n",
    "P(A\\mid B) = \\frac{P(B\\mid A)\\,P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "This is known as *Bayes' Theorem* or *Bayes' Rule*, and is important because it gives a formula for \"flipping\" conditional probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of model fitting, the Bayes' theorem is written:\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta} \\mid D) = \\frac{P(D\\mid \\boldsymbol{\\theta})P(\\boldsymbol{\\theta})}{P(D)}\n",
    "$$\n",
    "\n",
    "Technically all the probabilities should all be conditioned on the information $I$:\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta} \\mid D,I) = \\frac{P(D \\mid \\boldsymbol{\\theta},I)P(\\boldsymbol{\\theta} \\mid I)}{P(D \\mid I)}\n",
    "$$\n",
    "\n",
    "Recall $\\boldsymbol{\\theta}$ is the model we're interested in, $D$ is the observed data, and $I$ encodes all the prior information, including what led us to choose the particular model we're using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is controversial in that expression ?* \n",
    "\n",
    "- We have a probability distribution over model parameters. A frequentist would say this is meaningless!\n",
    "\n",
    "- The answer depends on the prior $P(\\theta\\mid I)$. This is the probability of the model parameters without any data: how are we supposed to know that?\n",
    "\n",
    "Nevertheless, applying Bayes' rule in this manner gives us a means of quantifying our knowledge of the parameters $\\theta$ given observed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 Exploring the Terms in Bayesian Inference\n",
    "\n",
    "We have four terms in the above expression, and we need to make sure we understand them:\n",
    "\n",
    "#### $P(\\boldsymbol{\\theta}\\mid D, I)$ is the *posterior*.\n",
    "This is the quantity we want to compute: our knowledge of the model given the data & background knowledge (including the choice of model).\n",
    "\n",
    "#### $P(D\\mid\\boldsymbol{\\theta},I)$ is the *likelihood*.\n",
    "This measures the probability of seeing our data given the model. This is identical to the quantity maximized in frequentist *maximum-likelihood* approaches.\n",
    "\n",
    "#### $P(\\boldsymbol{\\theta}\\mid I)$ is the *prior*.\n",
    "This encodes any knowledge we had about the answer before measuring the current data.\n",
    "\n",
    "#### $P(D\\mid I)$ is the *Fully Marginalized Likelihood* (or *Evidence*)\n",
    "You might prefer the acronym *FML* (it's also called the *Evidence* - namely the evidence that the data D was generated by the model - among other things). Its complete expression is:\n",
    "\n",
    "$$\n",
    "P(D\\mid I) = \\int P(D\\mid\\boldsymbol{\\theta}, I) \\, P(\\boldsymbol{\\theta}) \\, \\rm{d}\\boldsymbol{\\theta}\n",
    "$$\n",
    "\n",
    "In the context of **model fitting**, it acts as a normalization constant and in most cases can be ignored. In **model selection**, the FML can become important (but it is costly to calculate as you need to evaluate the likelihood for all the values of your parameters $\\boldsymbol{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 What is the Point?\n",
    "\n",
    "At first blush, this might all seem needlessly complicated. Why not simply maximize the likelihood and be done with it? Why multiply by a prior at all?\n",
    "\n",
    "- *Purity*: you quantify knowledge in terms of a probability, then follow the math to compute the answer. The fact that you need to specify a prior might be inconvenient, but we can't simply pretend it away.\n",
    "- *Parameter Uncertainties*: Whether frequentist or Bayesian, the maximum likelihood \"point estimate\" is only a small part of the picture. What we're really interested in scientifically is the uncertainty of the estimates. So simply reporting a point estimate is not appropriate. In frequentist approaches, \"error bars\" are generally computed from *Confidence Intervals*, which effectively measure the probability that the data encompass the true (fixed) value of the parameter, hence $P(\\hat{\\boldsymbol{\\theta}}\\mid\\boldsymbol{\\theta})$, rather than $P(\\boldsymbol{\\theta}\\mid D)$, which is effectively what we are interested in (and what is derived from the Bayesian approach). Note the difference: the Bayesian solution is a statement of probability about the parameter value given fixed bounds. The frequentist solution is a probability about the bounds given a fixed parameter value. This follows directly from the philosophical definitions of probability that the two approaches are based on.\n",
    "- *Marginalization and Nuisance Parameters*: Bayesian approaches offer a very natural way to systematically account for nuisance parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- In Bayesian statistics, the problem setting can be framed: we want to infer some probability about reality (e.g. the mass of a planet) given some data and some information about it. Mathematically this is done by computing the posterior probability distribution $𝑃(\\boldsymbol{\\theta} | 𝐷,𝐼)$, where $\\theta$ are the parameters of the model used to question nature, $D$ are the data that we obtained, and $I$ encapsulates our knowledge on the (parameters of the) problem.\n",
    "- In the context of model fitting, the Bayes theorem is expressed: \n",
    "$$\n",
    "P(\\boldsymbol{\\theta} \\mid D) = \\frac{P(D\\mid \\boldsymbol{\\theta})P(\\boldsymbol{\\theta})}{P(D)}\n",
    "$$\n",
    "- $P(\\boldsymbol{\\theta} \\mid D) $ is the *posterior* probability distribution, $P(D\\mid \\boldsymbol{\\theta})$ is the *likelihood*, $P(\\boldsymbol{\\theta})$ is the *prior* on the model parameters and $P(D)$ is the *fully marginalised likelihood* or *evidence*. \n",
    "- The Bayesian approach differs from the Frequentist's one in several conceptual aspects. In practice, one of the main difference is that in the frequentist's framework we search for the *best* parameters of a model and derive some confidence intervals, which give a statement about the proabability of a that a new measurement of a parameter falls in a given range. In a Bayesian framework, we derive the posterior probability distribution on a parameter (Which effectively is a non sense for a frequentist). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX References:\n",
    "\n",
    "**Chapter 5** (5.1, 5.2, 5.3, 5.8) of the book <a class=\"anchor\" id=\"book\"></a> *Statistics, data mining and Machine learning in astronomy* by Z. Ivezic et al. in Princeton Series in Modern Astronomy. \n",
    "\n",
    "- This notebook includes a large fraction of the material that J. Vander Plas gave during the \"Bayesian Methods in Astronomy workshop\", presented at the 227th meeting of the American Astronomical Society. The full repository with that material can be found on GitHub: http://github.com/jakevdp/AAS227Workshop\n",
    "\n",
    "- More insights on the differences between frequentist and Bayesian approaches: see [J. VanderPlass blog posts](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) \n",
    "\n",
    "- Jayes: [*Probability Theory: The Logic of Science*](http://bayes.wustl.edu/etj/prob/book.pdf).\n",
    "\n",
    "- For some approachable reading on frequentist vs. Bayesian uncertainties, I'd suggest [The Fallacy of Placing Confidence in Confidence Intervals](https://learnbayes.org/papers/confidenceIntervalsFallacy/), as well as Jake VanderPlast blog post on the topic, [Confidence, Credibility, and why Frequentism and Science do not Mix](http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/).\n",
    "\n",
    "- Andreon 2011 [Understanding better (some) astronomical data using Bayesian methods](https://arxiv.org/abs/1112.3652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
